{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richkaitoo/Heart-Attack-Risk-Prediction/blob/main/Heart_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nNWMJ-x9N5l"
      },
      "source": [
        "\n",
        "\n",
        "# Cardio Health Services Demand: A Comparative Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "778GbRqQ9N5l"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-10-17T20:47:28.656569Z",
          "iopub.status.busy": "2025-10-17T20:47:28.656201Z",
          "iopub.status.idle": "2025-10-17T20:47:28.662761Z",
          "shell.execute_reply": "2025-10-17T20:47:28.661463Z",
          "shell.execute_reply.started": "2025-10-17T20:47:28.656537Z"
        },
        "id": "t5mWu3WH9N5m",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "execution": {
          "iopub.execute_input": "2025-10-17T19:30:27.116449Z",
          "iopub.status.busy": "2025-10-17T19:30:27.116124Z",
          "iopub.status.idle": "2025-10-17T19:30:27.142237Z",
          "shell.execute_reply": "2025-10-17T19:30:27.141509Z",
          "shell.execute_reply.started": "2025-10-17T19:30:27.116398Z"
        },
        "id": "Tq48mndZ9N5m",
        "outputId": "81b5f904-dcf4-4bba-f7e6-f1d0a98631d3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print('Data source import complete.')\n",
        "data_path = kagglehub.dataset_download('johnsmith88/heart-disease-dataset')\n",
        "heart = pd.read_csv(data_path + '/heart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l5pV6p2wAdqP",
        "outputId": "55ee51af-a270-45b6-ba28-be7112ae3032"
      },
      "outputs": [],
      "source": [
        "heart.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTmdCZZH9N5m"
      },
      "source": [
        "### Data Structure\n",
        "\n",
        "This section explores the structure the hearts data that will be used for this analysis. This will be carried by using `heart.head()`, `heart.info()`, and `heart.describe()` to understand the data structure, including the number of rows, columns, data types, and summary statistics respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "execution": {
          "iopub.execute_input": "2025-10-17T19:47:00.824367Z",
          "iopub.status.busy": "2025-10-17T19:47:00.824088Z",
          "iopub.status.idle": "2025-10-17T19:47:00.866223Z",
          "shell.execute_reply": "2025-10-17T19:47:00.865378Z",
          "shell.execute_reply.started": "2025-10-17T19:47:00.824346Z"
        },
        "id": "NMN6Nrl_9N5m",
        "outputId": "b4adced0-e404-48be-bf6d-e764ccaba772",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(heart.head())\n",
        "print(heart.info())\n",
        "print(heart.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sqXo1KI9N5n"
      },
      "source": [
        "The output above describes the heart disease dataset, which includes a data preview of the first few rows, data structure details of 1025 rows and 14 columns with no missing values, data types that are a mix of integers and floats, and summary statistics that provide insights into the distribution and characteristics of each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H9Bd3Qr9N5n"
      },
      "source": [
        "### Checking for missing values\n",
        "\n",
        "In order to check if the dataset has missing values, the function `heart.isnull().sum()` is used identify missing values in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "execution": {
          "iopub.execute_input": "2025-10-17T19:46:34.382573Z",
          "iopub.status.busy": "2025-10-17T19:46:34.382242Z",
          "iopub.status.idle": "2025-10-17T19:46:34.389593Z",
          "shell.execute_reply": "2025-10-17T19:46:34.388558Z",
          "shell.execute_reply.started": "2025-10-17T19:46:34.382546Z"
        },
        "id": "6hl1VnLd9N5n",
        "outputId": "0bc6f1a6-f8b2-4206-d39a-fb8a63ecbbfd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(heart.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiskw3Di9N5n"
      },
      "source": [
        "The above suggests that, there are no missing values in the heart dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iwbM08a9N5n"
      },
      "source": [
        "### Visualizing the distribution of variables and outliers\n",
        "\n",
        "The distribution of data play roles in the accuracy of models. In order to determine whether some variables are either skewed, or normally distributed I use histograms, box plots, and density plots to visualize the distribution of numerical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5477
        },
        "execution": {
          "iopub.execute_input": "2025-10-17T20:15:13.843473Z",
          "iopub.status.busy": "2025-10-17T20:15:13.843103Z",
          "iopub.status.idle": "2025-10-17T20:15:19.215018Z",
          "shell.execute_reply": "2025-10-17T20:15:19.214203Z",
          "shell.execute_reply.started": "2025-10-17T20:15:13.843446Z"
        },
        "id": "BqHVPIsd9N5n",
        "outputId": "d0cbfe45-b7b6-46e5-d7e5-24542d78f785",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = heart.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create histograms and box plots\n",
        "for col in numerical_cols:\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    sns.histplot(heart[col], ax=ax[0], kde=True)\n",
        "    ax[0].set_title(f'Histogram of {col}')\n",
        "\n",
        "    sns.boxplot(heart[col], ax=ax[1])\n",
        "    ax[1].set_title(f'Box Plot of {col}')\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy7iirMm9N5o"
      },
      "source": [
        "### Examining relationships between variables\n",
        "\n",
        "This section will explore the visual relationship between then numerical variables. Heatmaps and correlation matrices will be used to examine the relationships between numerical variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "execution": {
          "iopub.execute_input": "2025-10-17T20:34:21.350096Z",
          "iopub.status.busy": "2025-10-17T20:34:21.34971Z",
          "iopub.status.idle": "2025-10-17T20:34:22.250296Z",
          "shell.execute_reply": "2025-10-17T20:34:22.249389Z",
          "shell.execute_reply.started": "2025-10-17T20:34:21.350063Z"
        },
        "id": "A27kqv7v9N5o",
        "outputId": "cb7567f6-6a7b-4dc1-9d25-6145c6107452",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "corr_matrix = heart.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "execution": {
          "iopub.execute_input": "2025-10-17T20:35:25.270483Z",
          "iopub.status.busy": "2025-10-17T20:35:25.269447Z",
          "iopub.status.idle": "2025-10-17T20:35:25.289841Z",
          "shell.execute_reply": "2025-10-17T20:35:25.288896Z",
          "shell.execute_reply.started": "2025-10-17T20:35:25.270443Z"
        },
        "id": "G45ME5hU9N5o",
        "outputId": "26f27fc0-fb37-42e1-967a-e51679d8a1d8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "corr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2lfkCT89N5o"
      },
      "source": [
        "From the above output, the following are observed.\n",
        "\n",
        "- *Strong positive correlations*: `cp` and `target` (0.43), `thalach` and `slope` (0.40), `exang` and `oldpeak` (-0.44), `target` and `thalach` (0.42)\n",
        "- *Strong negative correlations*: `target` and `sex` (-0.28), `exang` and `cp` (-0.40), `target` and `ca` (-0.38)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6F3dRozNRm6"
      },
      "source": [
        "### Processing Data For Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35hYIj7BUJr4"
      },
      "source": [
        "In this section, the data will be presented in a format that machine learning models can handle. The categorical variables will be one-hot encoded, and the variables will be transformed using scalar transformation.\n",
        "\n",
        "Before these preprocessing steps, the data will be split into training and test sets to avoid data leakage and introducing bias into the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-17T20:46:50.512327Z",
          "iopub.status.busy": "2025-10-17T20:46:50.51163Z",
          "iopub.status.idle": "2025-10-17T20:46:52.281091Z",
          "shell.execute_reply": "2025-10-17T20:46:52.280163Z",
          "shell.execute_reply.started": "2025-10-17T20:46:50.512291Z"
        },
        "id": "DO9WHo7J9N5o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(heart.drop('target', axis=1), heart['target'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r3uyq4QVUF9"
      },
      "source": [
        "The data has been split into a training set and a test set. Three preprocessing steps will be applied to the data:\n",
        "\n",
        "1. Binning the age into groups.\n",
        "2. One-hot encoding.\n",
        "2. Transforming data using scalar transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCjbC-zrZ3zt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, StandardScaler\n",
        "\n",
        "def preprocess_data(X_train, X_test):\n",
        "    categorical_variables = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "    numerical_columns = ['trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "\n",
        "    # Define preprocessing steps\n",
        "    categorical_preprocessor = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    numerical_preprocessor = StandardScaler()\n",
        "    age_preprocessor = KBinsDiscretizer(n_bins=6, encode='onehot-dense', strategy='uniform')\n",
        "\n",
        "    # Use ColumnTransformer to apply different preprocessing steps\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_preprocessor, numerical_columns),\n",
        "            ('age', age_preprocessor, ['age']),\n",
        "            ('cat', categorical_preprocessor, categorical_variables)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "    X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "    # Get the feature names\n",
        "    feature_names = []\n",
        "    feature_names += [f\"{col}\" for col in numerical_columns]\n",
        "    feature_names += [f\"age_{i+1}\" for i in range(6)]\n",
        "    for var in categorical_variables:\n",
        "        if var == 'age':\n",
        "            continue\n",
        "        categories = X_train[var].unique()\n",
        "        feature_names += [f\"{var}_{cat}\" for cat in categories]\n",
        "\n",
        "    return X_train_preprocessed, X_test_preprocessed, feature_names\n",
        "\n",
        "# Usage\n",
        "X_train_preprocessed, X_test_preprocessed, feature_names = preprocess_data(X_train, X_test)\n",
        "\n",
        "# Convert the preprocessed data to DataFrames with feature names\n",
        "X_train_df = pd.DataFrame(X_train_preprocessed, columns=feature_names)\n",
        "X_test_df = pd.DataFrame(X_test_preprocessed, columns=feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6X2yBs9W73x"
      },
      "source": [
        "The output above shows the training dataset that has been binned by age and one-hot encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz9XznseXsWH"
      },
      "source": [
        "# Modeling\n",
        "\n",
        "After preprocessing the data, the following section will present a comparative analysis of various classification models. These models were selected due to their widespread use and relevance in the literature. The models that will be adopted are:\n",
        "\n",
        "1. *Logistic Regression*: A linear model for binary classification problems.\n",
        "2. *Decision Trees*: A tree-based model that splits data into subsets based on feature values.\n",
        "3. *Random Forest*: An ensemble model that combines multiple decision trees to improve accuracy and robustness.\n",
        "4. *Support Vector Machines (SVMs)*: A linear or non-linear model that finds the optimal hyperplane to separate classes.\n",
        "5. *K-Nearest Neighbors (KNN)*: A model that classifies new instances based on the majority vote of their k-nearest neighbors.\n",
        "6. *Gradient Boosting*: An ensemble model that combines multiple weak models to create a strong predictive model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ABCjCKwnCAki"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_models(X_train_df, y_train, X_test_df, y_test):\n",
        "    # Define the models\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "        \"Linear Discriminant Analysis (LDA)\": LinearDiscriminantAnalysis(),\n",
        "        \"K-Nearest Neighbors (KNN, k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "        \"Decision Trees\": DecisionTreeClassifier(),\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"Support Vector Machines (SVMs)\": SVC(),\n",
        "        \"K-Nearest Neighbors (KNN, default k)\": KNeighborsClassifier(),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "    }\n",
        "\n",
        "    # Train and evaluate the models\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        results[name] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BLKeuv_oIXfc",
        "outputId": "a4316a42-e6e8-4ccd-e3b0-f8041aeabc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression, Accuracy: 0.795\n",
            "Model: Linear Discriminant Analysis (LDA), Accuracy: 0.820\n",
            "Model: K-Nearest Neighbors (KNN, k=3), Accuracy: 0.902\n",
            "Model: Decision Trees, Accuracy: 0.985\n",
            "Model: Random Forest, Accuracy: 0.985\n",
            "Model: Support Vector Machines (SVMs), Accuracy: 0.683\n",
            "Model: K-Nearest Neighbors (KNN, default k), Accuracy: 0.732\n",
            "Model: Gradient Boosting, Accuracy: 0.932\n"
          ]
        }
      ],
      "source": [
        "results = train_and_evaluate_models(X_train_df, y_train, X_test_df, y_test)\n",
        "for name, accuracy in results.items():\n",
        "    print(f\"Model: {name}, Accuracy: {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpsmeDd8hGWg"
      },
      "source": [
        "From the output above, the accuracy of each model on the test data. The models can be categorized as:\n",
        "\n",
        "- Top Models:\n",
        "    - Decision Trees: 98.5%\n",
        "    - Random Forest: 98.5%\n",
        "    - Gradient Boosting: 93.2%\n",
        "- Middle Models:\n",
        "    - K-Nearest Neighbors (KNN, k=3): 90.2%\n",
        "    - LDA: 82%\n",
        "    - Logistic Regression: 79.5%\n",
        "- Lower Models:\n",
        "    - K-Nearest Neighbors (KNN, default k): 73.2%\n",
        "    - Support Vector Machines (SVMs): 68.3%\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtwJG_4djJFi"
      },
      "source": [
        "The output looks okay and overfitting is not evident in any of the models. However, we will use cross-validation to assess whether any of the accuracies occurred by chance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SqmLq-K22W-9",
        "outputId": "7b642506-561a-485c-fefe-d8b3dd3e3351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression, Accuracy: 0.815\n",
            "  Cross-Validation Mean Accuracy: 0.871\n",
            "  Cross-Validation Std Accuracy: 0.028\n",
            "\n",
            "Model: Linear Discriminant Analysis (LDA), Accuracy: 0.824\n",
            "  Cross-Validation Mean Accuracy: 0.867\n",
            "  Cross-Validation Std Accuracy: 0.021\n",
            "\n",
            "Model: K-Nearest Neighbors (KNN, k=3), Accuracy: 0.951\n",
            "  Cross-Validation Mean Accuracy: 0.909\n",
            "  Cross-Validation Std Accuracy: 0.028\n",
            "\n",
            "Model: Decision Trees, Accuracy: 0.971\n",
            "  Cross-Validation Mean Accuracy: 0.976\n",
            "  Cross-Validation Std Accuracy: 0.019\n",
            "\n",
            "Model: Random Forest, Accuracy: 0.985\n",
            "  Cross-Validation Mean Accuracy: 0.982\n",
            "  Cross-Validation Std Accuracy: 0.016\n",
            "\n",
            "Model: Support Vector Machines (SVMs), Accuracy: 0.888\n",
            "  Cross-Validation Mean Accuracy: 0.929\n",
            "  Cross-Validation Std Accuracy: 0.023\n",
            "\n",
            "Model: K-Nearest Neighbors (KNN, default k), Accuracy: 0.863\n",
            "  Cross-Validation Mean Accuracy: 0.868\n",
            "  Cross-Validation Std Accuracy: 0.020\n",
            "\n",
            "Model: Gradient Boosting, Accuracy: 0.912\n",
            "  Cross-Validation Mean Accuracy: 0.938\n",
            "  Cross-Validation Std Accuracy: 0.026\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def train_and_evaluate_models(X_train_df, y_train, X_test_df, y_test):\n",
        "    # Define the models\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "        \"Linear Discriminant Analysis (LDA)\": LinearDiscriminantAnalysis(),\n",
        "        \"K-Nearest Neighbors (KNN, k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
        "        \"Decision Trees\": DecisionTreeClassifier(),\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"Support Vector Machines (SVMs)\": SVC(),\n",
        "        \"K-Nearest Neighbors (KNN, default k)\": KNeighborsClassifier(),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "    }\n",
        "\n",
        "    # Train and evaluate the models with cross-validation\n",
        "    results = {}\n",
        "    cv_results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train_df, y_train)\n",
        "        y_pred = model.predict(X_test_df)\n",
        "        results[name] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Perform cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train_df, y_train, cv=5, scoring='accuracy')\n",
        "        cv_results[name] = {\n",
        "            'mean_accuracy': cv_scores.mean(),\n",
        "            'std_accuracy': cv_scores.std(),\n",
        "            'accuracy_scores': cv_scores\n",
        "        }\n",
        "\n",
        "    return results, cv_results\n",
        "\n",
        "# Usage\n",
        "results, cv_results = train_and_evaluate_models(X_train_df, y_train, X_test_df, y_test)\n",
        "\n",
        "# Print the results\n",
        "for name, accuracy in results.items():\n",
        "    print(f\"Model: {name}, Accuracy: {accuracy:.3f}\")\n",
        "    print(f\"  Cross-Validation Mean Accuracy: {cv_results[name]['mean_accuracy']:.3f}\")\n",
        "    print(f\"  Cross-Validation Std Accuracy: {cv_results[name]['std_accuracy']:.3f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQoI1pktpeMd"
      },
      "source": [
        "Based on the results, the top tier models are:\n",
        "\n",
        "1. Random Forest: Accuracy: 0.985, Cross-Validation Mean Accuracy: 0.982\n",
        "2. Decision Trees: Accuracy: 0.971, Cross-Validation Mean Accuracy: 0.976\n",
        "3. K-Nearest Neighbors (KNN, k=3): Accuracy: 0.951, Cross-Validation Mean Accuracy: 0.909\n",
        "\n",
        "These three models stand out from the rest due to their high accuracy and cross-validation mean accuracy scores. They demonstrate strong performance and stability across different folds of the data.\n",
        "\n",
        "Hence, these three models will be selected for further hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdq_O-FAuhn6"
      },
      "source": [
        "The top three models selected are Random Forest, Decision Trees, and KNN. Due to the close performance of these models, I will perform hyperparameter tuning on these three models to see if any of them can surpass the others after optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6noOVt7arU0i",
        "outputId": "b7adf572-861c-4271-84d9-27b862d173c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Random Forest\n",
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Score: 0.9841\n",
            "\n",
            "Model: Decision Tree\n",
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Best Score: 0.9793\n",
            "\n",
            "Model: K-Nearest Neighbors\n",
            "Best Parameters: {'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
            "Best Score: 0.9890\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grids for top 3 models\n",
        "param_grids = {\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(),\n",
        "        \"params\": {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [None, 5, 10],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        \"model\": DecisionTreeClassifier(),\n",
        "        \"params\": {\n",
        "            'max_depth': [None, 5, 10],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        \"model\": KNeighborsClassifier(),\n",
        "        \"params\": {\n",
        "            'n_neighbors': [3, 5, 7],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'p': [1, 2]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform grid search for each model\n",
        "best_models = {}\n",
        "\n",
        "for name, model_info in param_grids.items():\n",
        "    grid_search = GridSearchCV(\n",
        "        model_info[\"model\"],\n",
        "        model_info[\"params\"],\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(X_train_df, y_train)\n",
        "\n",
        "    best_models[name] = {\n",
        "        \"best_params\": grid_search.best_params_,\n",
        "        \"best_score\": grid_search.best_score_,\n",
        "        \"best_estimator\": grid_search.best_estimator_\n",
        "    }\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "    print(\"Best Parameters:\", grid_search.best_params_)\n",
        "    print(f\"Best Score: {grid_search.best_score_:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF7E0xvkn8-k"
      },
      "source": [
        "After using the GridSearch to hyperparamter tune the Random Forest Mode, it was found out that, the best perform model is KNN with k=3, p=2.\n",
        "Comparing this to the best score of Random Forest, achieved by the model earlier, this is very close to the original score (0.9817). This indicate that the model is KNN has performed well, and the hyperparameter tuning did result in a significant improvement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhNSMEarpRQs"
      },
      "source": [
        "## Evaluating the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mwwl84Mxsf2M",
        "outputId": "e1c1bab8-d5ff-4086-e73c-2e02e326464b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "best_knn = best_models[\"K-Nearest Neighbors\"][\"best_estimator\"]\n",
        "y_pred = best_knn.predict(X_test_df)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gT_g34qTsxjb",
        "outputId": "32882194-b4ef-4a73-9e27-c6969fd7d33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[102   0]\n",
            " [  0 103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       102\n",
            "           1       1.00      1.00      1.00       103\n",
            "\n",
            "    accuracy                           1.00       205\n",
            "   macro avg       1.00      1.00      1.00       205\n",
            "weighted avg       1.00      1.00      1.00       205\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyG3trzowYCN"
      },
      "source": [
        "The above results indicates that in summary, the model achieved perfect performance on the test data, with no misclassifications. This is evident from the confusion matrix and the metrics (precision, recall, F1-score, and accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 216167,
          "sourceId": 477177,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
